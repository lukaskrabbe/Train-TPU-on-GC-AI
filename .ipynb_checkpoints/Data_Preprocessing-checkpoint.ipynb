{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import wget\n",
    "import os\n",
    "import shutil\n",
    "from google.cloud import storage\n",
    "import sys\n",
    "import math \n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context('notebook', font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Model\n",
    "from sklearn.utils import shuffle\n",
    "import umap\n",
    "\n",
    "\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BUCKET_NAME = 'product-classification'\n",
    "PROJECT_NAME = 'project_001_freisteller'\n",
    "path = 'gs://' + BUCKET_NAME + '/' + PROJECT_NAME + '/'\n",
    "IMAGE_PATH = 'images'\n",
    "MOUNTED_PATH = '/home/jupyter/product-classification/'\n",
    "\n",
    "\n",
    "CLASSFIED_FILE = 'train_classifier.csv'\n",
    "\n",
    "# Model Parameters:\n",
    "BATCH_SIZE = 512\n",
    "JOB_NAME = BUCKET_NAME + \"_\" + PROJECT_NAME + \"_\" + \"{}\".format(int(time.time()))\n",
    "\n",
    "label_names = {0: 'Zweifarbig',\n",
    "               1: 'Einfarbig',\n",
    "               2: 'Freisteller',\n",
    "               3: 'Ambiente',\n",
    "               4: 'Abma√üungen',\n",
    "               5: 'Sonstige'}\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "GC_PROJECT = 'bq-mak-yourhome' # REPLACE WITH YOUR PROJECT ID\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# do not change these\n",
    "os.environ['GC_PROJECT'] = GC_PROJECT\n",
    "os.environ['BUCKET'] = BUCKET_NAME\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.config.set) argument VALUE: Must be specified.\n",
      "Usage: gcloud config set SECTION/PROPERTY VALUE [optional flags]\n",
      "  optional flags may be  --help | --installation\n",
      "\n",
      "For detailed information on this command and its flags, run:\n",
      "  gcloud config set --help\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_core_data(df):\n",
    "    df = df.drop(['Detailbild14',\n",
    "                          'Detailbild50',\n",
    "                       'Detailbild62',\n",
    "                          'Freisteller (Test)',\n",
    "                          'Herstellerbild'], axis=1)\n",
    "\n",
    "    df = df[df['Klassifikation'].isin(['WOHNLANDSCHAFT',\n",
    "                                        'SOFA',\n",
    "                                        'SESSEL',\n",
    "                                        'HOCKER'])]\n",
    "\n",
    "    df = df[df['Warengruppe'].isin(['Hocker',\n",
    "                                    'Polsterecken',\n",
    "                                    'Schlafsofas',\n",
    "                                    'Sessel',\n",
    "                                    'Sofas',\n",
    "                                    'Wohnlandschaften'])]\n",
    "\n",
    "    df = df[df['Produktname'].notnull()]\n",
    "    df = df[df['Suchfarbe'].notnull()]\n",
    "    df = df.melt(id_vars=['Artikelnummer', 'Produktname', 'Produkttyp', 'Warengruppe', 'Klassifikation', 'Suchfarbe'], var_name='Imagetype', value_name=\"Image\")\n",
    "    df = df[df['Image'].notnull()]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remnove_Not_Available(df, not_av):\n",
    "    return df[~df['Image'].str.contains('|'.join(not_av))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_images(df, n):\n",
    "    i = 0\n",
    "    for val in df['Image'].values:\n",
    "        if i < n:\n",
    "            plt.imshow(io.imread(val))\n",
    "            plt.show()\n",
    "        else:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pic(pic):\n",
    "    try:\n",
    "        wget.download(pic, (MOUNTED_PATH+PROJECT_NAME+'/'+IMAGE_PATH))\n",
    "        \n",
    "    except:\n",
    "        print(\"ERROR: \"+ pic)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_df = pd.read_excel(path + CORE_FILE)\n",
    "classified_df = pd.read_csv(path + CLASSFIED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of core 110798\n",
      "Size of classified 959\n",
      "Size of df 959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "core_df = clean_core_data(core_df)\n",
    "core_df = remnove_Not_Available(core_df, ['6303722.jpg', '6303723.jpg', '6303721.jpg', '6303709.jpg'])\n",
    "core_df['ImageName'] = core_df['Image'].apply(lambda st: st[st.find(\"otto/\")+5:st.find(\"?$ads_\")])\n",
    "core_df = core_df.set_index('ImageName')\n",
    "core_df = core_df.groupby(core_df.index).first()\n",
    "\n",
    "classified_df['Label'] = classified_df['Label'].astype(str)\n",
    "classified_df = classified_df.set_index('Image')\n",
    "\n",
    "df = classified_df.join(core_df , how='left')\n",
    "df.index = df.index.rename('ImageName')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Size of core %d\" %(len(core_df)))\n",
    "print(\"Size of classified %d\" %(len(classified_df)))\n",
    "print(\"Size of df %d\" %(len(df)))\n",
    "print(\"\")\n",
    "plt_images(df, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mount point: /home/jupyter/product-classification\n",
      "Opening GCS connection...\n",
      "Opening bucket...\n",
      "Mounting file system...\n",
      "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: mount: running fusermount: exit status 1\n",
      "\n",
      "stderr:\n",
      "fusermount: mountpoint is not empty\n",
      "fusermount: if you are sure this is safe, use the 'nonempty' mount option\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter/product-classification/project_001_freisteller/images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-505d27cc4fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/bin/gcsfuse product-classification /home/jupyter/product-classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpictures_in_GCS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMOUNTED_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPROJECT_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mIMAGE_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpictures_in_GCS\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter/product-classification/project_001_freisteller/images/'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pictures_in_GCS = len([name for name in os.listdir((MOUNTED_PATH+PROJECT_NAME+'/'+IMAGE_PATH+'/'))])\n",
    "except FileNotFoundError:\n",
    "    !/usr/bin/gcsfuse product-classification /home/jupyter/product-classification\n",
    "\n",
    "pictures_in_GCS = len([name for name in os.listdir((MOUNTED_PATH+PROJECT_NAME+'/'+IMAGE_PATH+'/'))])\n",
    "\n",
    "if pictures_in_GCS < len(df):\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(\"Start download with:\")\n",
    "    print('%d CPU\\'s available' % num_cores)\n",
    "\n",
    "    results = Parallel(n_jobs=num_cores)(delayed(download_pic)(i) for i in df.groupby('Image').count().index.values)\n",
    "else:\n",
    "    print(\"pictures up to date!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(df, value_dict, size):\n",
    "    df = df.reset_index()\n",
    "    num_of_values = len(value_dict)\n",
    "    num_of_values_per_class = math.floor(size/num_of_values)\n",
    "    new_df = pd.DataFrame()\n",
    "    for idx, i in enumerate(df.groupby('Label')):\n",
    "        new_df = new_df.append(i[1][:num_of_values_per_class], ignore_index = True)\n",
    "    return new_df.set_index('ImageName')\n",
    "\n",
    "short_df = reshape(df, label_names, 50)\n",
    "#short_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = pd.to_numeric(df['Label']).map(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = (path +IMAGE_PATH + '/') + df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df[['path','Label']])) < 0.9\n",
    "\n",
    "train = train_set[msk]\n",
    "test = train_set[~msk]\n",
    "\n",
    "train.to_csv(path +'train_set.csv', header=False, index=False)\n",
    "test.to_csv(path +'eval_set.csv', header=False, index=False)\n",
    "pd.DataFrame(data=list(label_names.values())).to_csv(path +'labels.txt', sep=',',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incesnet = InceptionResNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "\n",
    "generator = ImageDataGenerator(rescale= 1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator.flow_from_dataframe(dataframe=short_df.reset_index(),\n",
    "                                    shuffle=False,\n",
    "                                    directory=(MOUNTED_PATH + PROJECT_NAME + '/' + IMAGE_PATH),\n",
    "                                    x_col='ImageName',\n",
    "                                    #y_col='Label',\n",
    "                                    #has_ext=True,\n",
    "                                    target_size=(299, 299),\n",
    "                                    batch_size=BATCH_SIZE,  \n",
    "                                    class_mode='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = incesnet.predict_generator(gen, steps=gen.n / BATCH_SIZE, verbose=1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = pd.DataFrame(encoded_features)\n",
    "print(len(encoded_features))\n",
    "encoded_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "decode_predictions( encoded_features,top = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = to_categorical(short_df['Label'])\n",
    "features = pd.merge(short_df['Label'].reset_index(), encoded_features, left_index=True, right_index=True).set_index('ImageName').drop('Label', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.10)\n",
    "\n",
    "print(\"Test-Size: %d\" % len(y_test))\n",
    "print(\"Train-Size: %d\" % len(y_train))\n",
    "print(\"Number of Features: %d\" % X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(label_names) == target.shape[1]\n",
    "\n",
    "print(\"Number of classes: %d\" % len(label_names))\n",
    "print('Labelnames:', label_names)\n",
    "print('Labelcounts:', {label_names[idx]: i for idx, i in enumerate(short_df.groupby('Label').count()['Artikelnummer'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
