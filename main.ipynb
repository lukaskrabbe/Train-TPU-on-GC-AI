{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification from scratch with TPUs on Cloud ML Engine using ResNet\n",
    "\n",
    "This notebook demonstrates how to do image classification from scratch on a flowers dataset using TPUs and the resnet trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GC_PROJECT =  # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'product-classification' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "PROJECT = 'project_001_freisteller'\n",
    "MODEL_VERSION = 'ResNet_v03'\n",
    "\n",
    "# do not change these\n",
    "os.environ['GC_PROJECT'] = GC_PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['MODEL_VERSION'] = MODEL_VERSION\n",
    "os.environ['TFVERSION'] = '1.14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $GC_PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TPU service account\n",
    "\n",
    "Allow Cloud ML Engine to access the TPU and bill to your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "SVC_ACCOUNT=$(curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\"  \\\n",
    "    https://ml.googleapis.com/v1/projects/${GC_PROJECT}:getConfig \\\n",
    "              | grep tpuServiceAccount | tr '\"' ' ' | awk '{print $3}' )\n",
    "              \n",
    "echo \"Enabling TPU service account $SVC_ACCOUNT to act as Cloud ML Service Agent\"\n",
    "gcloud projects add-iam-policy-binding $GC_PROJECT --member serviceAccount:$SVC_ACCOUNT --role roles/ml.serviceAgent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try preprocessing locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ${PWD}/local_test/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil cat gs://${BUCKET}/${PROJECT}/train_set.csv | head -5 > ${PWD}/local_test/input.csv\n",
    "gsutil cat gs://${BUCKET}/${PROJECT}/labels.txt | sort > ${PWD}/local_test/labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/mymodel\n",
    "\n",
    "python -m trainer.preprocess \\\n",
    "       --train_csv ${PWD}/local_test/input.csv \\\n",
    "       --validation_csv ${PWD}/local_test/input.csv \\\n",
    "       --labels_file ${PWD}/local_test/labels.txt \\\n",
    "       --project_id $PROJECT \\\n",
    "       --output_dir ${PWD}/local_test/out \\\n",
    "       --runner=DirectRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ${PWD}/local_test/out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run it over full training and evaluation datasets.  This will happen in Cloud Dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/mymodel\n",
    "    \n",
    "gsutil -m rm -rf gs://${BUCKET}/resnet/data\n",
    "python -m trainer.preprocess \\\n",
    "       --train_csv gs://${BUCKET}/${PROJECT}/train_set.csv \\\n",
    "       --validation_csv gs://${BUCKET}/${PROJECT}/eval_set.csv \\\n",
    "       --labels_file gs://${BUCKET}/${PROJECT}/labels.txt \\\n",
    "       --project_id $GC_PROJECT \\\n",
    "       --output_dir gs://${BUCKET}/${PROJECT}/resnet/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://console.cloud.google.com/dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/${PROJECT}/resnet/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on the Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo -n \"--num_train_images=$(gsutil cat gs://${BUCKET}/${PROJECT}/train_set.csv | wc -l)  \"\n",
    "echo -n \"--num_eval_images=$(gsutil cat gs://${BUCKET}/${PROJECT}/eval_set.csv | wc -l)  \"\n",
    "echo \"--num_label_classes=$(gsutil cat gs://${BUCKET}/${PROJECT}/labels.txt | wc -l)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "TOPDIR=gs://${BUCKET}/${PROJECT}/resnet\n",
    "OUTDIR=${TOPDIR}/trained\n",
    "JOBNAME=imgclass_$(date -u +%y%m%d_%H%M%S)\n",
    "\n",
    "\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR  # Comment out this line to continue training from the last time\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    " --region=$REGION \\\n",
    " --module-name=trainer.resnet_main \\\n",
    " --package-path=$(pwd)/mymodel/trainer \\\n",
    " --job-dir=$OUTDIR \\\n",
    " --staging-bucket=gs://$BUCKET \\\n",
    " --scale-tier=BASIC_TPU \\\n",
    " --runtime-version=$TFVERSION --python-version=3.5 \\\n",
    " -- \\\n",
    " --data_dir=${TOPDIR}/data \\\n",
    " --model_dir=${OUTDIR}/ \\\n",
    " --resnet_depth=18 \\\n",
    " --train_batch_size=128 --eval_batch_size=64 --skip_host_call=True \\\n",
    " --steps_per_eval=150 --train_steps=500 \\\n",
    " --num_train_images=865 --num_eval_images=94 --num_label_classes=6 \\\n",
    " --export_dir=${OUTDIR}/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this on CLOUD Command:\n",
    "    tensorboard --logdir=gs://product-classification/project_001_freisteller/resnet/trained/ --port=8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/${PROJECT}/resnet/trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=${PROJECT}\n",
    "TOPDIR=gs://${BUCKET}/${PROJECT}/resnet\n",
    "OUTDIR=${TOPDIR}/trained\n",
    "JOBNAME=${PROJECT}_$(date -u +%y%m%d_%H%M%S)\n",
    "\n",
    "\n",
    "MODEL_VERSION=${MODEL_VERSION}\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/${PROJECT}/resnet/trained/export/ | tail -1)\n",
    "echo \"Deleting/deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "\n",
    "# comment/uncomment the appropriate line to run. The first time around, you will need only the two create calls\n",
    "# But during development, you might need to replace a version by deleting the version and creating it again\n",
    "\n",
    "#gcloud ml-engine versions delete --quiet ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "#gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use saved_model_cli to find out what inputs the model expects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model expects image_bytes.  This is typically base64 encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head ${PWD}/local_test/labels.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import base64, sys, json\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "picture = '17881084.jpg'\n",
    "\n",
    "with open('/home/jupyter/' + PROJECT + '/local_test/labels.txt', 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "with tf.gfile.GFile('gs://' + BUCKET + '/' + PROJECT + '/images/'+ picture, 'rb') as ifp:\n",
    "    credentials = GoogleCredentials.get_application_default()\n",
    "    api = discovery.build('ml', 'v1', credentials=credentials, discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "    \n",
    "    request_data = {'instances':\n",
    "                    [\n",
    "                        {\"input\": {\"b64\": base64.b64encode(ifp.read()).decode('utf-8')}}\n",
    "                    ]}\n",
    "    parent = 'projects/%s/models/%s/versions/%s' % (GC_PROJECT, PROJECT, MODEL_VERSION)\n",
    "    response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "\n",
    "\n",
    "    img=mpimg.imread('/home/jupyter/' + BUCKET + '/' + PROJECT + '/images/' + picture)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(lines[response['predictions'][0]['probabilities'].index(max(response['predictions'][0]['probabilities']))])\n",
    "    \n",
    "    print(lines)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
